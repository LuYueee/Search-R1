D[DEBUG] Batch reward stats - mean: 1.8286, min: -0.6000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.7706, min: -0.9000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.8950, min: -0.5000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.0015, min: -0.7000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.0155, min: -0.5000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.9544, min: -0.7000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.7473, min: -1.1000, max: 4.9000
D[DEBUG] Batch reward stats - mean: 1.8424, min: -1.0000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.9760, min: -0.7000, max: 5.0000s
D[DEBUG] Batch reward stats - mean: 1.7698, min: -1.0000, max: 5.0000m
D[DEBUG] Batch reward stats - mean: 1.9328, min: -0.7000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.9046, min: -0.7000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 1.6935, min: -0.7000, max: 4.9000
D[DEBUG] Batch reward stats - mean: 1.8510, min: -1.0000, max: 5.0000
4"Initial validation metrics: {'val/test_score/nq': "
1(@)
epoch 0, step 1
D[DEBUG] Batch reward stats - mean: 1.8137, min: -1.1000, max: 5.0000
val/test_score/nq
1.8702337551123622
val/test_score/nq
1.8702337551123622
epoch 0, step 2v
D[DEBUG] Batch reward stats - mean: 1.8804, min: -1.1000, max: 5.0000
env/number_of_valid_search
	1.0015625
env/number_of_valid_search
	1.0015625
epoch 0, step 3C
D[DEBUG] Batch reward stats - mean: 1.9628, min: -1.1000, max: 5.0000
env/number_of_valid_search
0.987890625''
env/number_of_valid_search
0.987890625
epoch 0, step 4%0
D[DEBUG] Batch reward stats - mean: 1.8463, min: -1.1000, max: 5.0000/T<
env/number_of_valid_search
0.98515625
env/number_of_valid_search
0.98515625
epoch 0, step 5
D[DEBUG] Batch reward stats - mean: 1.9622, min: -1.0000, max: 5.0000
env/number_of_valid_search
0.97890625
env/number_of_valid_search
0.97890625
epoch 0, step 6tif
D[DEBUG] Batch reward stats - mean: 1.9688, min: -1.1000, max: 5.0000
env/number_of_valid_search
0.97265625
env/number_of_valid_search
0.97265625
epoch 0, step 7ooe
D[DEBUG] Batch reward stats - mean: 1.9073, min: -1.1000, max: 5.0000.
env/number_of_valid_search
0.96796875
env/number_of_valid_search
0.96796875
epoch 0, step 8
D[DEBUG] Batch reward stats - mean: 1.9401, min: -1.2000, max: 5.0000L
env/number_of_valid_search
0.970703125
env/number_of_valid_search
0.970703125
epoch 0, step 9F
D[DEBUG] Batch reward stats - mean: 1.8511, min: -1.1000, max: 5.0000\
env/number_of_valid_search
0.98984375
env/number_of_valid_search
0.98984375
epoch 0, step 10
D[DEBUG] Batch reward stats - mean: 1.9193, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.025
env/number_of_valid_search
1.025
epoch 0, step 11]
D[DEBUG] Batch reward stats - mean: 1.8757, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.008203125
env/number_of_valid_search
1.008203125
epoch 0, step 12
D[DEBUG] Batch reward stats - mean: 1.8411, min: -0.9000, max: 5.0000
env/number_of_valid_search
0.977734375
env/number_of_valid_search
0.977734375
epoch 0, step 13NN`V/
D[DEBUG] Batch reward stats - mean: 1.9723, min: -1.0000, max: 5.0000
env/number_of_valid_search
0.974609375
env/number_of_valid_search
0.974609375
epoch 0, step 14
D[DEBUG] Batch reward stats - mean: 1.8003, min: -1.1000, max: 5.0000
env/number_of_valid_search
0.997265625
env/number_of_valid_search
0.997265625
epoch 0, step 151
D[DEBUG] Batch reward stats - mean: 1.9300, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.007421875
env/number_of_valid_search
1.007421875
epoch 0, step 16
D[DEBUG] Batch reward stats - mean: 1.8863, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.014453125
env/number_of_valid_search
1.014453125
epoch 0, step 17
D[DEBUG] Batch reward stats - mean: 1.9186, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.005859375
env/number_of_valid_search
1.005859375
epoch 0, step 18ps[
D[DEBUG] Batch reward stats - mean: 1.9353, min: -1.1000, max: 5.0000=
env/number_of_valid_search
1.021484375
env/number_of_valid_search
1.021484375
epoch 0, step 19
D[DEBUG] Batch reward stats - mean: 2.0502, min: -1.0000, max: 5.0000
env/number_of_valid_search
1.003125
env/number_of_valid_search
1.003125
epoch 0, step 20!
D[DEBUG] Batch reward stats - mean: 1.8539, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.013671875
env/number_of_valid_search
1.013671875
epoch 0, step 21n
D[DEBUG] Batch reward stats - mean: 2.1409, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.014453125
env/number_of_valid_search
1.014453125
epoch 0, step 22R
D[DEBUG] Batch reward stats - mean: 2.0141, min: -1.1000, max: 5.0000Q?
env/number_of_valid_search
1.001171875
env/number_of_valid_search
1.001171875
epoch 0, step 23r
D[DEBUG] Batch reward stats - mean: 2.1233, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.044921875
env/number_of_valid_search
1.044921875
epoch 0, step 24
D[DEBUG] Batch reward stats - mean: 2.2964, min: -1.2000, max: 5.0000V
env/number_of_valid_search
1.041015625
env/number_of_valid_search
1.041015625
epoch 0, step 25
D[DEBUG] Batch reward stats - mean: 2.2578, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.046484375
env/number_of_valid_search
1.046484375
epoch 0, step 26W
D[DEBUG] Batch reward stats - mean: 2.3470, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.066015625
env/number_of_valid_search
1.066015625
epoch 0, step 27<
D[DEBUG] Batch reward stats - mean: 2.3950, min: -1.1000, max: 5.0000_
env/number_of_valid_search
	1.0671875-
env/number_of_valid_search
	1.0671875
epoch 0, step 28Wi
D[DEBUG] Batch reward stats - mean: 2.5548, min: -0.7000, max: 5.0000
env/number_of_valid_search
1.094140625
env/number_of_valid_search
1.094140625
epoch 0, step 29Na
D[DEBUG] Batch reward stats - mean: 2.7478, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.08515625
env/number_of_valid_search
1.08515625
epoch 0, step 30
D[DEBUG] Batch reward stats - mean: 2.6648, min: -0.9000, max: 5.0000
env/number_of_valid_search
	1.0671875
env/number_of_valid_search
	1.0671875
epoch 0, step 31
D[DEBUG] Batch reward stats - mean: 2.8072, min: -1.2000, max: 5.0000
env/number_of_valid_search
1.148046875
env/number_of_valid_search
1.148046875
epoch 0, step 32
D[DEBUG] Batch reward stats - mean: 2.8200, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.11953125
env/number_of_valid_search
1.11953125
epoch 0, step 33
D[DEBUG] Batch reward stats - mean: 2.8381, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.11953125
env/number_of_valid_search
1.11953125
epoch 0, step 34
D[DEBUG] Batch reward stats - mean: 2.7491, min: -0.9000, max: 5.00003f
env/number_of_valid_search
1.132421875
env/number_of_valid_search
1.132421875
epoch 0, step 35
D[DEBUG] Batch reward stats - mean: 2.9347, min: -0.7000, max: 5.0000
env/number_of_valid_search
1.080859375
env/number_of_valid_search
1.080859375
epoch 0, step 36
D[DEBUG] Batch reward stats - mean: 2.9799, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.084765625
env/number_of_valid_search
1.084765625
epoch 0, step 37
D[DEBUG] Batch reward stats - mean: 2.8734, min: -1.1000, max: 5.0000dA
env/number_of_valid_search
1.07265625
env/number_of_valid_search
1.07265625
epoch 0, step 38RC
D[DEBUG] Batch reward stats - mean: 2.9704, min: -1.1000, max: 5.0000
env/number_of_valid_search
	1.0484375
env/number_of_valid_search
	1.0484375
epoch 0, step 39
D[DEBUG] Batch reward stats - mean: 2.8392, min: -0.9000, max: 5.0000V
env/number_of_valid_search
1.06015625
env/number_of_valid_search
1.06015625
epoch 0, step 40
D[DEBUG] Batch reward stats - mean: 2.8816, min: -1.1000, max: 5.0000&
env/number_of_valid_search
1.032421875
env/number_of_valid_search
1.032421875
epoch 0, step 41H#:
D[DEBUG] Batch reward stats - mean: 2.9479, min: -1.1000, max: 5.0000g
env/number_of_valid_search
	1.0828125
env/number_of_valid_search
	1.0828125
epoch 0, step 427
D[DEBUG] Batch reward stats - mean: 2.9279, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.078125
env/number_of_valid_search
1.078125
epoch 0, step 43
D[DEBUG] Batch reward stats - mean: 3.0137, min: -0.7000, max: 5.0000
env/number_of_valid_search
1.058203125
env/number_of_valid_search
1.058203125
epoch 0, step 44dZg
D[DEBUG] Batch reward stats - mean: 2.8868, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.034375
env/number_of_valid_search
1.034375
epoch 0, step 45
D[DEBUG] Batch reward stats - mean: 2.8574, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.06171875
env/number_of_valid_search
1.06171875
epoch 0, step 46E,
D[DEBUG] Batch reward stats - mean: 2.8445, min: -0.9000, max: 5.0000
env/number_of_valid_search
1.065234375
env/number_of_valid_search
1.065234375
epoch 0, step 47e
D[DEBUG] Batch reward stats - mean: 2.8511, min: -0.7000, max: 5.0000
env/number_of_valid_search
1.047265625
env/number_of_valid_search
1.047265625
epoch 0, step 48&
D[DEBUG] Batch reward stats - mean: 2.7917, min: -1.1000, max: 5.0000
env/number_of_valid_search
1.040625
env/number_of_valid_search
1.040625
epoch 0, step 49|%G
D[DEBUG] Batch reward stats - mean: 3.0001, min: -0.9000, max: 5.0000
env/number_of_valid_search
	1.0328125
env/number_of_valid_search
	1.0328125
epoch 0, step 50W
D[DEBUG] Batch reward stats - mean: 2.8004, min: -1.1000, max: 5.0000
env/number_of_valid_search
0.97890625
env/number_of_valid_search
0.97890625
epoch 0, step 51
D[DEBUG] Batch reward stats - mean: 2.9987, min: -0.9000, max: 5.0000
env/number_of_valid_search
0.983984375
env/number_of_valid_search
0.983984375
epoch 0, step 52
D[DEBUG] Batch reward stats - mean: 2.9419, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.96875
env/number_of_valid_search
0.96875
epoch 0, step 53
D[DEBUG] Batch reward stats - mean: 2.8073, min: -0.8000, max: 5.0000@
env/number_of_valid_search
	0.9546875
env/number_of_valid_search
	0.9546875
epoch 0, step 54
D[DEBUG] Batch reward stats - mean: 2.9863, min: -1.1000, max: 5.0000
env/number_of_valid_search
0.927734375
env/number_of_valid_search
0.927734375
epoch 0, step 55hM	C/
D[DEBUG] Batch reward stats - mean: 2.9386, min: -0.9000, max: 5.0000
env/number_of_valid_search
0.907421875
env/number_of_valid_search
0.907421875
epoch 0, step 56N
D[DEBUG] Batch reward stats - mean: 2.9257, min: -0.9000, max: 5.0000k}2
env/number_of_valid_search
0.919921875
env/number_of_valid_search
0.919921875
epoch 0, step 57
D[DEBUG] Batch reward stats - mean: 2.9637, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.887109375
env/number_of_valid_search
0.887109375
epoch 0, step 58w
D[DEBUG] Batch reward stats - mean: 2.9381, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.871484375
env/number_of_valid_search
0.871484375
epoch 0, step 59!
D[DEBUG] Batch reward stats - mean: 2.8747, min: -0.9000, max: 5.00004
env/number_of_valid_search
	0.8765625
env/number_of_valid_search
	0.8765625
epoch 0, step 60`v
D[DEBUG] Batch reward stats - mean: 2.8678, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.8421875
env/number_of_valid_search
	0.8421875
epoch 0, step 61
D[DEBUG] Batch reward stats - mean: 2.9524, min: -0.7000, max: 5.0000Ao#7/
env/number_of_valid_search
0.85625
env/number_of_valid_search
0.85625
epoch 0, step 62I
D[DEBUG] Batch reward stats - mean: 2.9696, min: -0.7000, max: 5.0000gD
env/number_of_valid_search
0.869140625
env/number_of_valid_search
0.869140625
epoch 0, step 63
D[DEBUG] Batch reward stats - mean: 3.0745, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.86171875
env/number_of_valid_search
0.86171875
epoch 0, step 64?(G
D[DEBUG] Batch reward stats - mean: 2.9736, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.84296875
env/number_of_valid_search
0.84296875
epoch 0, step 65
D[DEBUG] Batch reward stats - mean: 2.8726, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.834765625
env/number_of_valid_search
0.834765625
epoch 0, step 66
D[DEBUG] Batch reward stats - mean: 2.8768, min: -0.7000, max: 5.0000r]
env/number_of_valid_search
0.81484375
env/number_of_valid_search
0.81484375
epoch 0, step 67-
D[DEBUG] Batch reward stats - mean: 3.0016, min: -0.3000, max: 5.0000
env/number_of_valid_search
	0.8078125
env/number_of_valid_search
	0.8078125
epoch 0, step 68
D[DEBUG] Batch reward stats - mean: 2.8810, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.790234375
env/number_of_valid_search
0.790234375
epoch 0, step 69+T
D[DEBUG] Batch reward stats - mean: 2.8361, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.80625
env/number_of_valid_search
0.80625
epoch 0, step 70
D[DEBUG] Batch reward stats - mean: 2.8605, min: -0.9000, max: 5.0000
env/number_of_valid_search
0.80625
env/number_of_valid_search
0.80625
epoch 0, step 71
D[DEBUG] Batch reward stats - mean: 2.8606, min: -0.6000, max: 5.0000B
env/number_of_valid_search
0.765625
env/number_of_valid_search
0.765625
epoch 0, step 72
D[DEBUG] Batch reward stats - mean: 2.8934, min: -1.1000, max: 5.0000m
env/number_of_valid_search
0.775
env/number_of_valid_search
0.775
epoch 0, step 73
D[DEBUG] Batch reward stats - mean: 2.8547, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.75703125
env/number_of_valid_search
0.75703125
epoch 0, step 74
D[DEBUG] Batch reward stats - mean: 2.7775, min: -0.6000, max: 5.0000^m=A.
env/number_of_valid_search
0.73828125
env/number_of_valid_search
0.73828125
epoch 0, step 75
D[DEBUG] Batch reward stats - mean: 2.8440, min: -0.5000, max: 5.0000Zyu
env/number_of_valid_search
0.721875
env/number_of_valid_search
0.721875
epoch 0, step 76
D[DEBUG] Batch reward stats - mean: 2.8328, min: -0.5000, max: 5.0000r
env/number_of_valid_search
0.72890625
env/number_of_valid_search
0.72890625
epoch 0, step 77
D[DEBUG] Batch reward stats - mean: 2.8789, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.71328125
env/number_of_valid_search
0.71328125
epoch 0, step 78
D[DEBUG] Batch reward stats - mean: 2.8932, min: -0.4000, max: 5.0000
env/number_of_valid_search
0.71171875
env/number_of_valid_search
0.71171875
epoch 0, step 79T
D[DEBUG] Batch reward stats - mean: 2.9247, min: -0.7000, max: 5.0000}
env/number_of_valid_search
0.668359375
env/number_of_valid_search
0.668359375
epoch 0, step 80
D[DEBUG] Batch reward stats - mean: 2.8248, min: -0.4000, max: 5.0000
env/number_of_valid_search
	0.6609375
env/number_of_valid_search
	0.6609375
epoch 0, step 81
D[DEBUG] Batch reward stats - mean: 2.8253, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.66875
env/number_of_valid_search
0.66875
epoch 0, step 82
D[DEBUG] Batch reward stats - mean: 2.8573, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.655859375
env/number_of_valid_search
0.655859375
epoch 0, step 83"
D[DEBUG] Batch reward stats - mean: 2.8435, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.67109375
env/number_of_valid_search
0.67109375
epoch 0, step 84(
D[DEBUG] Batch reward stats - mean: 2.8745, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.66640625
env/number_of_valid_search
0.66640625
epoch 0, step 85
D[DEBUG] Batch reward stats - mean: 2.9558, min: -0.3000, max: 5.0000
env/number_of_valid_search
0.668359375
env/number_of_valid_search
0.668359375
epoch 0, step 86
D[DEBUG] Batch reward stats - mean: 2.8895, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.6703125
env/number_of_valid_search
	0.6703125
epoch 0, step 87*o}9/
D[DEBUG] Batch reward stats - mean: 2.9206, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.658203125
env/number_of_valid_search
0.658203125
epoch 0, step 88
D[DEBUG] Batch reward stats - mean: 2.8900, min: -0.5000, max: 5.0000V
env/number_of_valid_search
0.671875
env/number_of_valid_search
0.671875
epoch 0, step 89
D[DEBUG] Batch reward stats - mean: 2.9403, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.6625
env/number_of_valid_search
0.6625
epoch 0, step 90
D[DEBUG] Batch reward stats - mean: 2.8767, min: -0.2000, max: 5.0000.
env/number_of_valid_search
0.673046875
env/number_of_valid_search
0.673046875
epoch 0, step 91
D[DEBUG] Batch reward stats - mean: 2.9302, min: -0.6000, max: 5.0000Y
env/number_of_valid_search
0.672265625
env/number_of_valid_search
0.672265625
epoch 0, step 92e/
D[DEBUG] Batch reward stats - mean: 2.8978, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.644140625
env/number_of_valid_search
0.644140625
epoch 0, step 93d
D[DEBUG] Batch reward stats - mean: 2.8728, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.6203125
env/number_of_valid_search
	0.6203125
epoch 0, step 94
D[DEBUG] Batch reward stats - mean: 2.7812, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.632421875
env/number_of_valid_search
0.632421875
epoch 0, step 95
D[DEBUG] Batch reward stats - mean: 2.8377, min: -0.7000, max: 5.0000/
env/number_of_valid_search
0.60546875
env/number_of_valid_search
0.60546875
epoch 0, step 96
D[DEBUG] Batch reward stats - mean: 2.9617, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.63203125
env/number_of_valid_search
0.63203125
epoch 0, step 97
D[DEBUG] Batch reward stats - mean: 2.8958, min: -0.5000, max: 5.0000
env/number_of_valid_search
	0.5578125
env/number_of_valid_search
	0.5578125
epoch 0, step 98
D[DEBUG] Batch reward stats - mean: 2.8889, min: -0.4000, max: 5.0000
env/number_of_valid_search
0.53515625
env/number_of_valid_search
0.53515625
epoch 0, step 99
D[DEBUG] Batch reward stats - mean: 2.7614, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.540234375
env/number_of_valid_search
0.540234375
epoch 0, step 100
D[DEBUG] Batch reward stats - mean: 2.7779, min: -0.7000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.5604, min: -0.2000, max: 5.0000
C[DEBUG] Batch reward stats - mean: 2.6221, min: 0.0000, max: 5.0000
C[DEBUG] Batch reward stats - mean: 2.8799, min: 0.0000, max: 5.0000 
D[DEBUG] Batch reward stats - mean: 2.7646, min: -0.2000, max: 5.0000
C[DEBUG] Batch reward stats - mean: 2.8334, min: 0.0000, max: 5.0000|
C[DEBUG] Batch reward stats - mean: 2.9704, min: 0.0000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.8668, min: -0.1000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.8184, min: -0.5000, max: 5.0000pNR
D[DEBUG] Batch reward stats - mean: 2.8204, min: -0.4000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.6405, min: -0.4000, max: 5.0000Wg
C[DEBUG] Batch reward stats - mean: 2.8798, min: 0.0000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.8050, min: -0.1000, max: 5.0000
D[DEBUG] Batch reward stats - mean: 2.6644, min: -0.1000, max: 5.0000v
D[DEBUG] Batch reward stats - mean: 2.6619, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.546875
env/number_of_valid_search
0.546875
epoch 0, step 101
D[DEBUG] Batch reward stats - mean: 2.7588, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.49140625
val/test_score/nq
2.770566689143639
env/number_of_valid_search
0.49140625
val/test_score/nq
2.770566689143639
epoch 0, step 102
D[DEBUG] Batch reward stats - mean: 2.7780, min: -0.2000, max: 5.0000's
env/number_of_valid_search
0.48671875
env/number_of_valid_search
0.48671875
epoch 0, step 103
D[DEBUG] Batch reward stats - mean: 2.8851, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.487890625
env/number_of_valid_search
0.487890625
epoch 0, step 104
D[DEBUG] Batch reward stats - mean: 2.8296, min: -0.8000, max: 5.0000
env/number_of_valid_search
0.497265625
env/number_of_valid_search
0.497265625
epoch 0, step 105
D[DEBUG] Batch reward stats - mean: 2.7835, min: -0.6000, max: 5.0000RI
env/number_of_valid_search
0.53046875
env/number_of_valid_search
0.53046875
epoch 0, step 1061
D[DEBUG] Batch reward stats - mean: 2.8553, min: -0.3000, max: 5.0000cP
env/number_of_valid_search
	0.5109375
env/number_of_valid_search
	0.5109375
epoch 0, step 107
D[DEBUG] Batch reward stats - mean: 2.7991, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.468359375
env/number_of_valid_search
0.468359375
epoch 0, step 108Z
D[DEBUG] Batch reward stats - mean: 2.9419, min: -0.6000, max: 5.0000
env/number_of_valid_search
	0.4953125
env/number_of_valid_search
	0.4953125
epoch 0, step 109
D[DEBUG] Batch reward stats - mean: 2.8343, min: -0.7000, max: 5.0000mi
env/number_of_valid_search
0.562890625
env/number_of_valid_search
0.562890625
epoch 0, step 110
D[DEBUG] Batch reward stats - mean: 2.7683, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.483984375
env/number_of_valid_search
0.483984375
epoch 0, step 111+
D[DEBUG] Batch reward stats - mean: 2.9650, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.508203125
env/number_of_valid_search
0.508203125
epoch 0, step 112
D[DEBUG] Batch reward stats - mean: 2.6971, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.499609375
env/number_of_valid_search
0.499609375
epoch 0, step 113<
D[DEBUG] Batch reward stats - mean: 2.7178, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.516015625
env/number_of_valid_search
0.516015625
epoch 0, step 114O!
D[DEBUG] Batch reward stats - mean: 2.7079, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.4453125
env/number_of_valid_search
	0.4453125
epoch 0, step 115O
D[DEBUG] Batch reward stats - mean: 2.7265, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.45
env/number_of_valid_search
0.45
epoch 0, step 116
D[DEBUG] Batch reward stats - mean: 2.7201, min: -0.5000, max: 5.0000X
env/number_of_valid_search
0.377734375
env/number_of_valid_search
0.377734375
epoch 0, step 117D_
D[DEBUG] Batch reward stats - mean: 2.5056, min: -0.3000, max: 5.00006m
env/number_of_valid_search
0.408984375
env/number_of_valid_search
0.408984375
epoch 0, step 118
D[DEBUG] Batch reward stats - mean: 2.4088, min: -0.3000, max: 5.0000
env/number_of_valid_search
0.31953125
env/number_of_valid_search
0.31953125
epoch 0, step 119
D[DEBUG] Batch reward stats - mean: 2.5108, min: -0.5000, max: 5.0000uo
env/number_of_valid_search
	0.2515625
env/number_of_valid_search
	0.2515625
epoch 0, step 120b
D[DEBUG] Batch reward stats - mean: 2.5252, min: -0.7000, max: 5.0000A
env/number_of_valid_search
0.25234375
env/number_of_valid_search
0.25234375
epoch 0, step 121<
D[DEBUG] Batch reward stats - mean: 2.5091, min: -0.6000, max: 5.0000[
env/number_of_valid_search
0.322265625
env/number_of_valid_search
0.322265625
epoch 0, step 122
D[DEBUG] Batch reward stats - mean: 2.6813, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.317578125
env/number_of_valid_search
0.317578125
epoch 0, step 123
D[DEBUG] Batch reward stats - mean: 2.6437, min: -0.5000, max: 5.0000
env/number_of_valid_search
0.35390625
env/number_of_valid_search
0.35390625
epoch 0, step 124
D[DEBUG] Batch reward stats - mean: 2.6080, min: -0.4000, max: 5.0000]
env/number_of_valid_search
	0.2828125
env/number_of_valid_search
	0.2828125
epoch 0, step 125
D[DEBUG] Batch reward stats - mean: 2.4698, min: -0.5000, max: 5.0000Z
env/number_of_valid_search
0.33828125
env/number_of_valid_search
0.33828125
epoch 0, step 126
D[DEBUG] Batch reward stats - mean: 2.6615, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.329296875
env/number_of_valid_search
0.329296875
epoch 0, step 127
D[DEBUG] Batch reward stats - mean: 2.7278, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.341015625
env/number_of_valid_search
0.341015625
epoch 0, step 128^Q
D[DEBUG] Batch reward stats - mean: 2.5852, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.37890625
env/number_of_valid_search
0.37890625
epoch 0, step 129
D[DEBUG] Batch reward stats - mean: 2.6782, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.385546875
env/number_of_valid_search
0.385546875
epoch 0, step 130<|
D[DEBUG] Batch reward stats - mean: 2.6956, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.401953125
env/number_of_valid_search
0.401953125
epoch 0, step 131a
D[DEBUG] Batch reward stats - mean: 2.6177, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.413671875
env/number_of_valid_search
0.413671875
epoch 0, step 132iF
D[DEBUG] Batch reward stats - mean: 2.6390, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.39296875
env/number_of_valid_search
0.39296875
epoch 0, step 133
D[DEBUG] Batch reward stats - mean: 2.6654, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.41484375
env/number_of_valid_search
0.41484375
epoch 0, step 134
D[DEBUG] Batch reward stats - mean: 2.3693, min: -0.7000, max: 5.0000B
env/number_of_valid_search
0.356640625
env/number_of_valid_search
0.356640625
epoch 0, step 135
D[DEBUG] Batch reward stats - mean: 2.2253, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.30390625
env/number_of_valid_search
0.30390625
epoch 0, step 136
D[DEBUG] Batch reward stats - mean: 1.8224, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.21796875
env/number_of_valid_search
0.21796875
epoch 0, step 137
D[DEBUG] Batch reward stats - mean: 1.6291, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.10625
env/number_of_valid_search
0.10625
epoch 0, step 138
D[DEBUG] Batch reward stats - mean: 1.5671, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.12109375
env/number_of_valid_search
0.12109375
epoch 0, step 139
D[DEBUG] Batch reward stats - mean: 1.6163, min: -0.7000, max: 5.0000>
env/number_of_valid_search
0.148046875
env/number_of_valid_search
0.148046875
epoch 0, step 140W
D[DEBUG] Batch reward stats - mean: 1.4554, min: -0.7000, max: 5.0000c
env/number_of_valid_search
0.158203125
env/number_of_valid_search
0.158203125
epoch 0, step 141
D[DEBUG] Batch reward stats - mean: 1.4358, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.285546875
env/number_of_valid_search
0.285546875
epoch 0, step 142
D[DEBUG] Batch reward stats - mean: 1.3208, min: -0.7000, max: 5.0000^
env/number_of_valid_search
0.30234375
env/number_of_valid_search
0.30234375
epoch 0, step 143
D[DEBUG] Batch reward stats - mean: 1.1305, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.36875
env/number_of_valid_search
0.36875
epoch 0, step 144O
D[DEBUG] Batch reward stats - mean: 1.0928, min: -0.7000, max: 5.0000?
env/number_of_valid_search
0.328125
env/number_of_valid_search
0.328125
epoch 0, step 145
D[DEBUG] Batch reward stats - mean: 0.8334, min: -0.7000, max: 5.0000"sJW/
env/number_of_valid_search
0.34375
env/number_of_valid_search
0.34375
epoch 0, step 146w:A
D[DEBUG] Batch reward stats - mean: 0.9681, min: -0.7000, max: 5.0000\
env/number_of_valid_search
0.403515625
env/number_of_valid_search
0.403515625
epoch 0, step 147
D[DEBUG] Batch reward stats - mean: 0.3625, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.3109375
env/number_of_valid_search
	0.3109375
epoch 0, step 148
D[DEBUG] Batch reward stats - mean: 0.1552, min: -0.7000, max: 5.00008
env/number_of_valid_search
0.45546875
env/number_of_valid_search
0.45546875
epoch 0, step 149
D[DEBUG] Batch reward stats - mean: 0.0652, min: -0.7000, max: 5.0000x
env/number_of_valid_search
0.51015625
env/number_of_valid_search
0.51015625
epoch 0, step 150
D[DEBUG] Batch reward stats - mean: 0.0612, min: -0.7000, max: 5.0000S
env/number_of_valid_search
0.56875
env/number_of_valid_search
0.56875
epoch 0, step 151
D[DEBUG] Batch reward stats - mean: 0.0411, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.517578125
env/number_of_valid_search
0.517578125
epoch 0, step 152
E[DEBUG] Batch reward stats - mean: -0.0711, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.521875
env/number_of_valid_search
0.521875
epoch 0, step 153
E[DEBUG] Batch reward stats - mean: -0.1318, min: -0.7000, max: 5.00007;
env/number_of_valid_search
0.521875
env/number_of_valid_search
0.521875
epoch 0, step 154	
E[DEBUG] Batch reward stats - mean: -0.1664, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.52421875
env/number_of_valid_search
0.52421875
epoch 1, step 155
E[DEBUG] Batch reward stats - mean: -0.1405, min: -0.7000, max: 5.0000&
env/number_of_valid_search
0.467578125
env/number_of_valid_search
0.467578125
epoch 1, step 156R
E[DEBUG] Batch reward stats - mean: -0.0909, min: -0.7000, max: 5.0000v
env/number_of_valid_search
0.44296875
env/number_of_valid_search
0.44296875
epoch 1, step 157r2
E[DEBUG] Batch reward stats - mean: -0.0021, min: -0.6000, max: 5.0000
env/number_of_valid_search
	0.4015625
env/number_of_valid_search
	0.4015625
epoch 1, step 158~
D[DEBUG] Batch reward stats - mean: 0.2548, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.42578125
env/number_of_valid_search
0.42578125
epoch 1, step 159
D[DEBUG] Batch reward stats - mean: 0.2786, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.508203125
env/number_of_valid_search
0.508203125
epoch 1, step 160
D[DEBUG] Batch reward stats - mean: 0.5208, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.561328125
env/number_of_valid_search
0.561328125
epoch 1, step 161$
D[DEBUG] Batch reward stats - mean: 0.7736, min: -0.6000, max: 5.0000Oe
env/number_of_valid_search
	0.6015625
env/number_of_valid_search
	0.6015625
epoch 1, step 162
D[DEBUG] Batch reward stats - mean: 0.9629, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.63203125
env/number_of_valid_search
0.63203125
epoch 1, step 163
D[DEBUG] Batch reward stats - mean: 1.0419, min: -0.6000, max: 5.0000Bi*1/
env/number_of_valid_search
0.616796875
env/number_of_valid_search
0.616796875
epoch 1, step 164
D[DEBUG] Batch reward stats - mean: 0.9304, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.60703125
env/number_of_valid_search
0.60703125
epoch 1, step 165
D[DEBUG] Batch reward stats - mean: 1.1456, min: -0.7000, max: 5.0000Pvgq/
env/number_of_valid_search
0.629296875
env/number_of_valid_search
0.629296875
epoch 1, step 166oh
D[DEBUG] Batch reward stats - mean: 1.0602, min: -0.7000, max: 5.0000P_
env/number_of_valid_search
	0.7140625
env/number_of_valid_search
	0.7140625
epoch 1, step 167
D[DEBUG] Batch reward stats - mean: 0.9622, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.721484375
env/number_of_valid_search
0.721484375
epoch 1, step 168
D[DEBUG] Batch reward stats - mean: 1.0123, min: -0.6000, max: 5.00005
env/number_of_valid_search
0.565234375
env/number_of_valid_search
0.565234375
epoch 1, step 169
D[DEBUG] Batch reward stats - mean: 0.7837, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.55390625
env/number_of_valid_search
0.55390625
epoch 1, step 170
D[DEBUG] Batch reward stats - mean: 0.8422, min: -0.6000, max: 5.0000o
env/number_of_valid_search
0.572265625
env/number_of_valid_search
0.572265625
epoch 1, step 1714
D[DEBUG] Batch reward stats - mean: 0.7776, min: -0.7000, max: 5.0000HR#
env/number_of_valid_search
0.614453125
env/number_of_valid_search
0.614453125
epoch 1, step 172j
D[DEBUG] Batch reward stats - mean: 0.7074, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.637109375
env/number_of_valid_search
0.637109375
epoch 1, step 173
D[DEBUG] Batch reward stats - mean: 0.4889, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.657421875
env/number_of_valid_search
0.657421875
epoch 1, step 174
D[DEBUG] Batch reward stats - mean: 0.6649, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.612109375
env/number_of_valid_search
0.612109375
epoch 1, step 175
D[DEBUG] Batch reward stats - mean: 0.9064, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.625
env/number_of_valid_search
0.625
epoch 1, step 176
D[DEBUG] Batch reward stats - mean: 0.8699, min: -0.6000, max: 5.0000
env/number_of_valid_search
	0.5828125
env/number_of_valid_search
	0.5828125
epoch 1, step 177
D[DEBUG] Batch reward stats - mean: 0.8659, min: -0.6000, max: 5.0000
env/number_of_valid_search
0.524609375
env/number_of_valid_search
0.524609375
epoch 1, step 178
D[DEBUG] Batch reward stats - mean: 0.8661, min: -0.6387, max: 5.0000
env/number_of_valid_search
0.43125
env/number_of_valid_search
0.43125
epoch 1, step 179
D[DEBUG] Batch reward stats - mean: 0.5966, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.4296875
env/number_of_valid_search
	0.4296875
epoch 1, step 180d
D[DEBUG] Batch reward stats - mean: 0.6408, min: -0.7000, max: 5.0000
env/number_of_valid_search
	0.3703125
env/number_of_valid_search
	0.3703125
epoch 1, step 181:
D[DEBUG] Batch reward stats - mean: 0.8185, min: -0.7000, max: 5.0000z
env/number_of_valid_search
0.398046875
env/number_of_valid_search
0.398046875
epoch 1, step 182
D[DEBUG] Batch reward stats - mean: 0.6553, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.329296875
env/number_of_valid_search
0.329296875
epoch 1, step 183
D[DEBUG] Batch reward stats - mean: 0.6522, min: -0.7000, max: 5.0000
env/number_of_valid_search
0.28359375
env/number_of_valid_search
0.28359375
epoch 1, step 184
D[DEBUG] Batch reward stats - mean: 0.6048, min: -0.6000, max: 5.0000fS?
env/number_of_valid_search
	0.2515625
env/number_of_valid_search
	0.2515625
epoch 1, step 185xJ}^/
D[DEBUG] Batch reward stats - mean: 0.5338, min: -0.9000, max: 5.0000
env/number_of_valid_search
0.186328125
env/number_of_valid_search
0.186328125
epoch 1, step 186
D[DEBUG] Batch reward stats - mean: 0.3663, min: -0.5000, max: 4.0000
env/number_of_valid_search
0.146484375
env/number_of_valid_search
0.146484375
epoch 1, step 187
D[DEBUG] Batch reward stats - mean: 0.2866, min: -0.4000, max: 4.0000
env/number_of_valid_search
0.119921875
env/number_of_valid_search
0.119921875
epoch 1, step 188
D[DEBUG] Batch reward stats - mean: 0.2547, min: -0.4000, max: 4.5556
env/number_of_valid_search
0.15
env/number_of_valid_search
0.15
epoch 1, step 1899
D[DEBUG] Batch reward stats - mean: 0.2813, min: -0.5000, max: 4.0000s`.
env/number_of_valid_search
	0.1328125
env/number_of_valid_search
	0.1328125
epoch 1, step 190
D[DEBUG] Batch reward stats - mean: 0.1888, min: -0.5000, max: 4.0000
env/number_of_valid_search
	0.1359375
env/number_of_valid_search
	0.1359375
epoch 1, step 191
D[DEBUG] Batch reward stats - mean: 0.0666, min: -0.5000, max: 4.0000=
env/number_of_valid_search
0.07421875
env/number_of_valid_search
0.07421875
epoch 1, step 192
E[DEBUG] Batch reward stats - mean: -0.0974, min: -0.5000, max: 4.0000
env/number_of_valid_search
0.041796875
env/number_of_valid_search
0.041796875
epoch 1, step 193
E[DEBUG] Batch reward stats - mean: -0.3161, min: -0.5000, max: 4.0000y
env/number_of_valid_search
0.01875
env/number_of_valid_search
0.01875
epoch 1, step 194
E[DEBUG] Batch reward stats - mean: -0.3643, min: -0.4000, max: 1.6000
env/number_of_valid_search
	0.0078125
env/number_of_valid_search
	0.0078125
epoch 1, step 195
E[DEBUG] Batch reward stats - mean: -0.3810, min: -0.4000, max: 1.6000
env/number_of_valid_search
global_seqlen/minmax_diff
env/number_of_valid_search
global_seqlen/minmax_diff
epoch 1, step 1967~5p/
E[DEBUG] Batch reward stats - mean: -0.3771, min: -0.4000, max: 1.6000+6
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 197
E[DEBUG] Batch reward stats - mean: -0.3674, min: -0.4000, max: 1.6000
env/number_of_valid_search
actor/pg_clipfrac
env/number_of_valid_search
actor/pg_clipfrac
epoch 1, step 198_CUa/
E[DEBUG] Batch reward stats - mean: -0.3781, min: -0.4000, max: 3.6000}\
env/number_of_valid_search
timing_s/ref
env/number_of_valid_search
timing_s/ref
epoch 1, step 199
E[DEBUG] Batch reward stats - mean: -0.3839, min: -0.4000, max: 1.6000I
env/number_of_valid_search
timing_s/ref
env/number_of_valid_search
timing_s/ref
epoch 1, step 200F%K&/
E[DEBUG] Batch reward stats - mean: -0.3872, min: -0.4000, max: 1.6000z
E[DEBUG] Batch reward stats - mean: -0.3615, min: -0.4000, max: 1.6000{
E[DEBUG] Batch reward stats - mean: -0.3807, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3667, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3448, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3411, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3458, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3318, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3370, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3589, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3385, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3339, min: -0.4000, max: 1.60003_
E[DEBUG] Batch reward stats - mean: -0.3536, min: -0.4000, max: 1.60003'L6/
E[DEBUG] Batch reward stats - mean: -0.3698, min: -0.4000, max: 1.6000
E[DEBUG] Batch reward stats - mean: -0.3677, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_per_token_ms/adv
env/number_of_valid_search
1(@)
epoch 1, step 201
E[DEBUG] Batch reward stats - mean: -0.3792, min: -0.4000, max: 1.60006
env/number_of_valid_search
timing_s/testing
val/test_score/nq
-0.3522693503348689
env/number_of_valid_search
timing_s/testing
val/test_score/nq
-0.3522693503348689
epoch 1, step 202
E[DEBUG] Batch reward stats - mean: -0.3789, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/step
env/number_of_valid_search
timing_s/step
epoch 1, step 2039Ew1/
E[DEBUG] Batch reward stats - mean: -0.3930, min: -0.4000, max: 1.6000H
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 204;V
E[DEBUG] Batch reward stats - mean: -0.3789, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 205
E[DEBUG] Batch reward stats - mean: -0.3716, min: -0.4000, max: 1.6000
env/number_of_valid_search
_step
env/number_of_valid_search
_step
epoch 1, step 206$z
E[DEBUG] Batch reward stats - mean: -0.3693, min: -0.4000, max: 2.2667
env/number_of_valid_search
response_length/mean
env/number_of_valid_search
response_length/mean
epoch 1, step 207
E[DEBUG] Batch reward stats - mean: -0.3768, min: -0.4000, max: 1.6000B
env/number_of_valid_search
 timing_per_token_ms/update_actor
env/number_of_valid_search
 timing_per_token_ms/update_actor
epoch 1, step 208
E[DEBUG] Batch reward stats - mean: -0.3943, min: -0.4000, max: 1.2000
env/number_of_valid_search
 timing_per_token_ms/update_actor
env/number_of_valid_search
 timing_per_token_ms/update_actor
epoch 1, step 209
E[DEBUG] Batch reward stats - mean: -0.3836, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 210f
E[DEBUG] Batch reward stats - mean: -0.3646, min: -0.4000, max: 1.6000{	
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 211'
E[DEBUG] Batch reward stats - mean: -0.3638, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/update_actor
env/number_of_valid_search
timing_s/update_actor
epoch 1, step 212)
E[DEBUG] Batch reward stats - mean: -0.3841, min: -0.4000, max: 1.6000a
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 213
E[DEBUG] Batch reward stats - mean: -0.3706, min: -0.4000, max: 1.6000\Z
env/number_of_valid_search
global_seqlen/balanced_max
env/number_of_valid_search
global_seqlen/balanced_max
epoch 1, step 214
E[DEBUG] Batch reward stats - mean: -0.3724, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/update_actor
env/number_of_valid_search
timing_s/update_actor
epoch 1, step 215O
E[DEBUG] Batch reward stats - mean: -0.3904, min: -0.4000, max: 1.6000\
env/number_of_valid_search
global_seqlen/minmax_diff
env/number_of_valid_search
global_seqlen/minmax_diff
epoch 1, step 216p
E[DEBUG] Batch reward stats - mean: -0.3776, min: -0.4000, max: 1.6000
env/number_of_valid_search
global_seqlen/balanced_min
env/number_of_valid_search
timing_s/gen
epoch 1, step 217
E[DEBUG] Batch reward stats - mean: -0.3854, min: -0.4000, max: 1.2000
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 218Wb
E[DEBUG] Batch reward stats - mean: -0.3742, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/ref
env/number_of_valid_search
timing_s/ref
epoch 1, step 219A)
E[DEBUG] Batch reward stats - mean: -0.3784, min: -0.4000, max: 1.6000
env/number_of_valid_search
actor/ppo_kl
env/number_of_valid_search
actor/ppo_kl
epoch 1, step 220i.
E[DEBUG] Batch reward stats - mean: -0.3724, min: -0.4000, max: 1.6000r
env/number_of_valid_search
global_seqlen/balanced_max
env/number_of_valid_search
global_seqlen/balanced_max
epoch 1, step 221BZ
E[DEBUG] Batch reward stats - mean: -0.3852, min: -0.4000, max: 1.6000
env/number_of_valid_search
global_seqlen/max
env/number_of_valid_search
global_seqlen/max
epoch 1, step 222!P,\/
E[DEBUG] Batch reward stats - mean: -0.3732, min: -0.4000, max: 1.6000
env/number_of_valid_search
 timing_per_token_ms/update_actor
env/number_of_valid_search
1(@)
epoch 1, step 223
E[DEBUG] Batch reward stats - mean: -0.3763, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 224o
E[DEBUG] Batch reward stats - mean: -0.3859, min: -0.4000, max: 1.2000
env/number_of_valid_search
_timestamp
env/number_of_valid_search
_timestamp
epoch 1, step 225M
E[DEBUG] Batch reward stats - mean: -0.3815, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 226
E[DEBUG] Batch reward stats - mean: -0.3818, min: -0.4000, max: 1.2000
env/number_of_valid_search
actor/kl_coef
env/number_of_valid_search
actor/kl_coef
epoch 1, step 227
E[DEBUG] Batch reward stats - mean: -0.3867, min: -0.4000, max: 1.6000N,
env/number_of_valid_search
_timestamp
env/number_of_valid_search
_timestamp
epoch 1, step 228
E[DEBUG] Batch reward stats - mean: -0.3870, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/update_actor
env/number_of_valid_search
timing_s/update_actor
epoch 1, step 2291$
E[DEBUG] Batch reward stats - mean: -0.3773, min: -0.4000, max: 1.6000!
env/number_of_valid_search
global_seqlen/max
env/number_of_valid_search
global_seqlen/max
epoch 1, step 230w=
E[DEBUG] Batch reward stats - mean: -0.3708, min: -0.4000, max: 1.6000w<QO.
env/number_of_valid_search
_runtime
env/number_of_valid_search
_runtime
epoch 1, step 231
E[DEBUG] Batch reward stats - mean: -0.3904, min: -0.4000, max: 1.6000
env/number_of_valid_search
global_seqlen/min
env/number_of_valid_search
global_seqlen/min
epoch 1, step 232
E[DEBUG] Batch reward stats - mean: -0.3846, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 233
E[DEBUG] Batch reward stats - mean: -0.3742, min: -0.4000, max: 3.6000T
env/number_of_valid_search
actor/pg_loss
env/number_of_valid_search
actor/pg_loss
epoch 1, step 234
E[DEBUG] Batch reward stats - mean: -0.3680, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 235
E[DEBUG] Batch reward stats - mean: -0.3867, min: -0.4000, max: 1.6000w
env/number_of_valid_search
critic/score/mean
env/number_of_valid_search
critic/score/mean
epoch 1, step 2369
E[DEBUG] Batch reward stats - mean: -0.3703, min: -0.4000, max: 1.6000=
env/number_of_valid_search
timing_per_token_ms/ref
env/number_of_valid_search
timing_per_token_ms/ref
epoch 1, step 237Vbw
E[DEBUG] Batch reward stats - mean: -0.3841, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 238
E[DEBUG] Batch reward stats - mean: -0.3841, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/update_actor
env/number_of_valid_search
timing_s/update_actor
epoch 1, step 239
E[DEBUG] Batch reward stats - mean: -0.3758, min: -0.4000, max: 1.60004
env/number_of_valid_search
_step
env/number_of_valid_search
_step
epoch 1, step 240&
E[DEBUG] Batch reward stats - mean: -0.3786, min: -0.4000, max: 1.6000-
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 241
E[DEBUG] Batch reward stats - mean: -0.3727, min: -0.4000, max: 1.6000
env/number_of_valid_search
 timing_per_token_ms/update_actor
env/number_of_valid_search
 timing_per_token_ms/update_actor
epoch 1, step 242PFvv/
E[DEBUG] Batch reward stats - mean: -0.3841, min: -0.4000, max: 1.6000W
env/number_of_valid_search
_timestamp
env/number_of_valid_search
_timestamp
epoch 1, step 243
E[DEBUG] Batch reward stats - mean: -0.3615, min: -0.4000, max: 1.6000
env/number_of_valid_search
global_seqlen/min
env/number_of_valid_search
global_seqlen/min
epoch 1, step 244
E[DEBUG] Batch reward stats - mean: -0.3732, min: -0.4000, max: 1.6000@
env/number_of_valid_search
timing_s/ref
env/number_of_valid_search
timing_s/ref
epoch 1, step 245{*
E[DEBUG] Batch reward stats - mean: -0.3898, min: -0.4000, max: 1.6000v
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 246>IFz/
E[DEBUG] Batch reward stats - mean: -0.3849, min: -0.4000, max: 1.2000
env/number_of_valid_search
global_seqlen/minmax_diff
env/number_of_valid_search
global_seqlen/minmax_diff
epoch 1, step 247:
E[DEBUG] Batch reward stats - mean: -0.3846, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_per_token_ms/adv
env/number_of_valid_search
timing_per_token_ms/adv
epoch 1, step 248
E[DEBUG] Batch reward stats - mean: -0.3844, min: -0.4000, max: 1.2000d
env/number_of_valid_search
global_seqlen/max
env/number_of_valid_search
global_seqlen/max
epoch 1, step 249
E[DEBUG] Batch reward stats - mean: -0.3753, min: -0.4000, max: 1.6000H
env/number_of_valid_search
timing_s/ref
env/number_of_valid_search
timing_s/ref
epoch 1, step 250b
E[DEBUG] Batch reward stats - mean: -0.3922, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 251
E[DEBUG] Batch reward stats - mean: -0.3885, min: -0.4000, max: 1.2000,D*
env/number_of_valid_search
actor/kl_coef
env/number_of_valid_search
actor/kl_coef
epoch 1, step 252
E[DEBUG] Batch reward stats - mean: -0.3789, min: -0.4000, max: 1.6000
env/number_of_valid_search
timing_s/adv
env/number_of_valid_search
timing_s/adv
epoch 1, step 253
E[DEBUG] Batch reward stats - mean: -0.3688, min: -0.4000, max: 1.6000H
env/number_of_valid_search
timing_s/gen
env/number_of_valid_search
timing_s/gen
epoch 1, step 254
E[DEBUG] Batch reward stats - mean: -0.3677, min: -0.4000, max: 3.6000
env/number_of_valid_search
timing_s/ref
env/number_of_valid_search
timing_s/ref
epoch 1, step 255
